{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "ignore = ['mr','quite','mmm','sort','actually','cause','sir','gonna','lad','shh','ha','uh','ah','ahhh','ooh','ya', 'so', 'got', 'that', 'this', '000', 'em', 'huh', 'aye', 'dum', 'la', 'ssh', 'okay', 'ok', 'gotta', 'hmm', 'aw', 'ow', 'also', 'yes', 'ah', 'said', 'well', 'would', 'yeah', 'two', 'shut','till', 'shall','john', 'mrs', 'ya', 'gotta', 'bit', 'hi', 'outta', 'bye', 'ii', 'aah','um', 'whoa', 'wanna','wow','uh']\n",
    "for x in ignore:\n",
    "    STOPWORDS.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = fetch_20newsgroups(subset='test', categories=['alt.atheism', 'comp.graphics', 'rec.motorcycles', 'sci.space', 'talk.politics.guns'])\n",
    "documents = corpus.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1940-disney = 0\n",
    "# 1950-disney = 1\n",
    "# 1960-disney = 2\n",
    "# 1970-disney = 3\n",
    "# 1980-disney = 4\n",
    "# 1990-disney = 5\n",
    "# 2000-disney = 6\n",
    "# 2010-disney = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Attilio\\Desktop\\progettone\\word cloud subtitles\\clean_subtitles\\\\subtitle disney\\Disney Animation\\2010'\n",
    "\n",
    "duemila_disney_file = []\n",
    "for x, y, z in os.walk(path):\n",
    "    for a in z:\n",
    "      #  if \".srt\" in a:\n",
    "        duemila_disney_file.append(x+'\\\\'+a)\n",
    "\n",
    "\n",
    "for srt_file in duemila_disney_file:\n",
    "    with open(srt_file,encoding=\"utf-8\", errors = 'ignore') as f:\n",
    "        srt_file_as_string = f.read()\n",
    "    data.append(srt_file_as_string)\n",
    "    target.append(7)\n",
    "print(len(data))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Attilio\\\\Desktop\\\\progettone\\\\word cloud subtitles\\\\clean_subtitles\\\\\\\\subtitle disney\\\\Disney Animation\\\\1970\\\\A tale of two critters 1977.srt',\n",
       " 'C:\\\\Users\\\\Attilio\\\\Desktop\\\\progettone\\\\word cloud subtitles\\\\clean_subtitles\\\\\\\\subtitle disney\\\\Disney Animation\\\\1970\\\\Herbie.Goes.to.Monte.Carlo 1977.srt',\n",
       " 'C:\\\\Users\\\\Attilio\\\\Desktop\\\\progettone\\\\word cloud subtitles\\\\clean_subtitles\\\\\\\\subtitle disney\\\\Disney Animation\\\\1970\\\\Superdad 1973.srt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duemila_disney_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codice alejandro correlazione\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from tsr_functions import *\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_words(X, y, nwords, featnames, tsr_function=information_gain_positive):\n",
    "    nD,nF = X.shape\n",
    "    positives = y.sum()\n",
    "    negatives = nD - positives\n",
    "\n",
    "    # computes the 4-cell contingency tables for each feature\n",
    "    TP = np.asarray((X[y==1]>0).sum(axis=0)).flatten()\n",
    "    FN = positives - TP\n",
    "    FP = np.asarray((X[y==0]>0).sum(axis=0)).flatten()\n",
    "    TN = negatives - FP\n",
    "    _4cell = [ContTable(tp=TP[i], tn=TN[i], fp=FP[i], fn=FN[i]) for i in range(nF)]\n",
    "\n",
    "    # applies the tsr_function to the 4-cell counters\n",
    "    feat_informativeness = np.array(list(map(tsr_function, _4cell)))\n",
    "\n",
    "    top_relevant_terms = np.argsort(-feat_informativeness)[:nwords]\n",
    "    feat_names = np.asarray(featnames)[top_relevant_terms]\n",
    "    feat_informativeness = feat_informativeness[top_relevant_terms]\n",
    "\n",
    "    return list(zip(feat_names, feat_informativeness))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4,\n",
       "       4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=1, stop_words = STOPWORDS, max_df=.65)\n",
    "X = tfidf.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 8)\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(target.reshape(-1, 1))\n",
    "nC = Y.shape[1]\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: gay (0.155), 300 (0.141), drunk (0.130), spots (0.097), flows (0.096), thumping (0.084), twitter (0.084), clover (0.084), mightiest (0.084), supercolossal (0.084), russian (0.084), spaces (0.084), persisted (0.084), phooey (0.084), provoked (0.084), unprotected (0.084), birdies (0.084), aviation (0.084), promptly (0.084), bombers (0.084), nestled (0.084), housefly (0.084), forbidding (0.084), tremendous (0.080), planted (0.080), struggle (0.080), cure (0.080), gypsy (0.080), deer (0.080), facing (0.069), shattered (0.069), menace (0.069), compare (0.069), quaint (0.069), destruction (0.069), merry (0.068), feet (0.065), mellow (0.056), existed (0.056), colossal (0.056), subconscious (0.056), formidable (0.056), acquainted (0.056), earthquake (0.056), whirl (0.056), spite (0.056), conquer (0.056), suffered (0.056), blasting (0.056), counselor (0.056)\n",
      "class 1: immediately (0.122), dee (0.101), gracious (0.099), wings (0.098), nightingale (0.096), pardons (0.096), grandchildren (0.096), lily (0.096), shorten (0.096), reliable (0.096), cuttin (0.096), marked (0.096), chimneys (0.096), ho (0.095), smiling (0.094), pompous (0.089), tis (0.089), maid (0.080), uhhuh (0.077), subjects (0.072), gay (0.072), improved (0.072), peaceful (0.072), certainly (0.069), grow (0.069), taller (0.068), fiddlefaddle (0.068), dreadfully (0.068), joyful (0.068), pets (0.068), ribbon (0.068), slippers (0.068), ribbons (0.068), darlings (0.068), excellency (0.068), sample (0.068), imperial (0.068), lovely (0.065), shoo (0.062), child (0.061), sweep (0.061), faith (0.061), clean (0.059), ought (0.059), terrible (0.057), heavens (0.056), vicious (0.056), thus (0.056), frightfully (0.055), twas (0.055)\n",
      "class 2: pocus (0.118), soot (0.118), hhhow (0.118), bungling (0.118), wholesome (0.118), hocus (0.118), barging (0.118), mile (0.096), surely (0.092), toes (0.092), brawn (0.089), eleven (0.089), inspection (0.089), bewitched (0.089), jungles (0.089), pupil (0.089), blockhead (0.089), flick (0.089), blimey (0.089), pike (0.089), gizzard (0.089), blinkin (0.077), fiddle (0.077), bloomin (0.077), nature (0.069), pop (0.069), downright (0.068), jove (0.068), violent (0.068), animal (0.067), de (0.065), gives (0.065), creature (0.063), wolves (0.061), sporting (0.061), chimney (0.061), bully (0.061), mangy (0.061), sakes (0.061), colonel (0.061), acts (0.061), steady (0.059), forgotten (0.059), nothin (0.059), nonsense (0.057), eight (0.057), indeed (0.056), george (0.056), givin (0.056), confound (0.056)\n",
      "class 3: lecture (0.118), rue (0.118), traveled (0.115), responsibility (0.100), camp (0.092), grueling (0.089), ducks (0.089), coo (0.089), lifetime (0.088), drivers (0.077), rounds (0.077), guard (0.076), 20 (0.071), backing (0.068), mechanic (0.068), ahold (0.068), rolled (0.068), tie (0.067), ohh (0.067), spend (0.065), test (0.065), 30 (0.065), miles (0.063), position (0.063), straighten (0.061), dizzy (0.061), error (0.061), goods (0.061), yards (0.061), clowns (0.061), wondering (0.059), begin (0.057), beach (0.056), races (0.056), gentleman (0.056), avenue (0.056), someplace (0.056), bail (0.056), deprive (0.055), goldsboro (0.055), aaaaaahhhhh (0.055), heaving (0.055), unions (0.055), overlooked (0.055), aaaaaaahhhhh (0.055), philly (0.055), phelps (0.055), skis (0.055), goodyear (0.055), aa (0.055)\n",
      "class 4: miserable (0.099), wanderin (0.096), interfered (0.096), pups (0.096), lovesick (0.096), distinguished (0.096), vocabulary (0.096), nasty (0.094), foot (0.089), walkin (0.080), nail (0.080), pipsqueak (0.080), fools (0.079), silly (0.073), adore (0.072), chow (0.068), lurk (0.068), residence (0.068), mutt (0.068), riffraff (0.068), cauldron (0.055), swimmin (0.055), mistaken (0.055), harp (0.055), trout (0.055), troubled (0.055), nogood (0.055), dastardly (0.055), overgrown (0.055), hound (0.055), runt (0.055), anxious (0.055), greedy (0.055), possessed (0.055), allow (0.053), delightful (0.052), farewell (0.052), beloved (0.048), madam (0.048), ay (0.047), peg (0.047), uses (0.047), caring (0.047), rescued (0.047), rubbish (0.047), fourteen (0.047), catastrophe (0.047), dyin (0.047), closely (0.047), wanders (0.046)\n",
      "class 5: baba (0.147), presents (0.115), prayer (0.087), aim (0.087), proven (0.085), dos (0.085), amour (0.085), bozo (0.085), smiled (0.085), byebye (0.066), grateful (0.064), patient (0.062), reporting (0.062), faraway (0.062), bravest (0.062), bean (0.061), streets (0.056), swell (0.056), snake (0.056), pride (0.056), sin (0.056), refunds (0.056), pressures (0.056), plaything (0.056), outdoors (0.056), hasty (0.056), hatching (0.056), adored (0.056), shallow (0.056), refuses (0.056), immortal (0.056), temple (0.056), seam (0.056), havoc (0.056), giddyap (0.056), afar (0.056), precedes (0.056), grovel (0.056), boarding (0.056), tissue (0.056), disturbs (0.056), camels (0.056), spending (0.056), alarms (0.056), shamed (0.056), ludicrous (0.056), richmond (0.056), singe (0.056), mistletoe (0.056), noodle (0.056)\n",
      "class 6: twins (0.119), scary (0.114), grease (0.098), engage (0.098), spoke (0.094), fired (0.082), piece (0.080), useless (0.079), tip (0.079), usually (0.079), nibble (0.077), surplus (0.077), cuddly (0.077), bottoms (0.077), obliged (0.077), mutiny (0.077), hid (0.077), spelled (0.077), pronounce (0.077), proposal (0.077), lure (0.077), triple (0.077), coffee (0.077), fake (0.076), butter (0.070), pet (0.070), tired (0.065), remind (0.065), heh (0.063), proof (0.061), swinging (0.061), aliens (0.061), ted (0.061), filed (0.061), chef (0.061), volcano (0.061), ruining (0.060), rights (0.060), listening (0.060), title (0.059), dessert (0.059), fish (0.058), 800 (0.057), inspire (0.057), utmost (0.057), experimental (0.057), illustration (0.057), iceland (0.057), acorn (0.057), hospitality (0.057)\n",
      "class 7: ugh (0.127), heading (0.102), cameras (0.099), saying (0.098), wrench (0.098), different (0.098), actual (0.094), connected (0.094), super (0.091), favorite (0.080), racer (0.080), loved (0.080), hearing (0.079), crash (0.079), sang (0.077), zombie (0.077), meanwhile (0.077), superpower (0.077), buying (0.077), random (0.077), racers (0.077), mixing (0.077), fading (0.077), blessing (0.077), tech (0.077), oldest (0.077), argh (0.077), multiple (0.077), data (0.077), sparkly (0.077), nickel (0.077), traffic (0.077), literally (0.077), technically (0.077), parent (0.076), asking (0.072), amazing (0.071), totally (0.070), putting (0.067), test (0.067), space (0.066), nope (0.065), fix (0.063), awesome (0.062), climbing (0.061), backup (0.061), bravery (0.061), doors (0.060), leaves (0.060), working (0.060)\n"
     ]
    }
   ],
   "source": [
    "nwords = 50\n",
    "for i in range(nC):\n",
    "    # getting the 10 most relevant terms for each class according to the (positive only) correlation to the\n",
    "    # group label, as quantified by information gain\n",
    "    class_i_relevant = get_relevant_words(X, Y[:,i], nwords, tfidf.get_feature_names())\n",
    "    print(f'class {i}: ' + ', '.join([f'{word} ({rel:.3f})' for word, rel in class_i_relevant]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
